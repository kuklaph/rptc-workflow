---
description: Interactive discovery and brainstorming with PM collaboration
---

# RPTC: Research Phase

**You are the research partner, NOT the decision maker.**
The user is the **project manager** - they have final sign-off authority.

**Arguments**: Topic/work item to research (e.g., "authentication system", "payment processing")

## Core Mission

Act as an intelligent brainstorming partner who:

- Asks probing questions to understand scope and requirements
- Identifies best practices and potential gotchas
- Suggests considerations the PM might not have thought about
- Helps flesh out what we're really trying to build

**Key Principle**: Keep asking questions until you have a SOLID understanding. Don't rush to solutions.

## Step 0a: Load Configuration

**Load RPTC configuration from `.claude/settings.json`:**

1. **Check if settings file exists**:
   - Use Read tool to read `.claude/settings.json`
   - If file doesn't exist or can't be read, use defaults (skip to step 3)

2. **Parse configuration** (extract these fields):
   - `rptc.defaultThinkingMode` ‚Üí THINKING_MODE (default: "think")
   - `rptc.artifactLocation` ‚Üí ARTIFACT_LOC (default: ".rptc")
   - `rptc.researchOutputFormat` ‚Üí OUTPUT_FORMAT (default: "html")
   - `rptc.htmlReportTheme` ‚Üí HTML_THEME (default: "dark")
   - `rptc.discord.notificationsEnabled` ‚Üí DISCORD_ENABLED (default: false)
   - `rptc.discord.webhookUrl` ‚Üí DISCORD_WEBHOOK (default: "")
   - `rptc.discord.verbosity` ‚Üí DISCORD_VERBOSITY (default: "summary")

3. **Create Discord notification helper function**:

```bash
notify_discord() {
  local message="$1"
  local min_verbosity="${2:-summary}"  # summary, detailed, or verbose

  # Check if notifications enabled
  if [ "$DISCORD_ENABLED" != "true" ] || [ -z "$DISCORD_WEBHOOK" ]; then
    return 0  # Silent skip
  fi

  # Check verbosity level
  case "$DISCORD_VERBOSITY" in
    summary)
      if [ "$min_verbosity" != "summary" ]; then
        return 0  # Skip this notification
      fi
      ;;
    detailed)
      if [ "$min_verbosity" = "verbose" ]; then
        return 0  # Skip verbose-only notifications
      fi
      ;;
    verbose)
      # Always send
      ;;
  esac

  # Send notification (fail-safe, never block workflow)
  if ! bash "${CLAUDE_PLUGIN_ROOT}/skills/discord-notify/scripts/notify.sh" \
    "$DISCORD_WEBHOOK" "$message" 2>/dev/null; then
    echo "‚ö†Ô∏è  Discord notification failed (continuing workflow)" >&2
  fi
}
```

**Use these values throughout the command execution.**

## Step 0c: Initialize TODO Tracking

**Initialize TodoWrite for research workflow.**

```json
{
  "tool": "TodoWrite",
  "todos": [
    {
      "content": "Complete interactive discovery",
      "status": "pending",
      "activeForm": "Conducting interactive discovery"
    },
    {
      "content": "Complete research (codebase and/or web)",
      "status": "pending",
      "activeForm": "Conducting research"
    },
    {
      "content": "Present findings inline",
      "status": "pending",
      "activeForm": "Presenting findings"
    }
  ]
}
```

**Important TodoWrite Rules**:
- Mark tasks "in_progress" when starting
- Mark tasks "completed" immediately after finishing
- Only ONE task should be "in_progress" at a time
- When user requests save (later message): dynamically add "Save research report" todo

## Step 0d: Intelligent Query Analysis

**Analyze the research topic/query to determine research scope.**

**Query Classification Heuristics:**

1. **Codebase-Only Indicators** (use Explore agent):
   - Keywords: "our", "this project", "existing", "current implementation"
   - Keywords: "where is", "how does our", "find in codebase", "locate"
   - Keywords: "refactor", "improve existing", "clean up", "understand current"
   - Example: "How does our authentication system work?"
   - Example: "Where are API endpoints defined?"

2. **Web-Only Indicators** (use master-research-agent):
   - Keywords: "best practices", "industry standard", "comparison", "compare"
   - Keywords: "new library", "latest", "modern", "current state of", "trends"
   - Keywords: "what's popular", "recommendations", "which tool/library"
   - Keywords: "how do other teams/companies", "common approach", "typical"
   - Keywords: "performance benchmarks", "security standards", "OWASP", "compliance"
   - Example: "Best practices for OAuth 2.0 implementation"
   - Example: "Compare React state management libraries 2025"

3. **Hybrid Indicators** (use BOTH agents in parallel):
   - Contains both codebase AND web research keywords
   - Example: "How does our auth compare to OWASP standards?"
   - Example: "Should we refactor to use latest Next.js patterns?"

**Classification Logic:**

```text
IF (query contains codebase keywords AND web keywords):
  RESEARCH_SCOPE = "hybrid"
ELSE IF (query contains web keywords):
  RESEARCH_SCOPE = "web"
ELSE IF (query contains codebase keywords):
  RESEARCH_SCOPE = "codebase"
ELSE:
  RESEARCH_SCOPE = "codebase" (conservative default)
```

**Set Variable**: RESEARCH_SCOPE = "codebase" | "web" | "hybrid"

**Display Classification**:
```text
üìä Query Analysis:
  Research scope: [RESEARCH_SCOPE value]
  Agent(s): [Explore | master-research-agent | Both]
```

## Step 0: Load Reference Materials

Load SOPs using fallback chain (highest priority first):

1. **Check project SOPs**: `.rptc/sop/`
2. **Check user global SOPs**: `~/.claude/global/sop/`
3. **Use plugin defaults**: `${CLAUDE_PLUGIN_ROOT}/sop/`

**SOPs to reference**:

- Architecture patterns: For design decisions
- Testing guide: For test strategy considerations
- Security: For security implications

**How to reference**:

```bash
# Try to read in order, use first one found:
1. .rptc/sop/architecture-patterns.md
2. ~/.claude/global/sop/architecture-patterns.md
3. ${CLAUDE_PLUGIN_ROOT}/sop/architecture-patterns.md
```

**Only reference SOPs when needed** - don't front-load everything. Consult them when:

- Making architecture decisions
- Discussing test strategies
- Identifying security concerns
- Choosing design patterns

## Research Process

### Phase 1: Interactive Discovery (REQUIRED)

**Update TodoWrite**: Mark "Complete interactive discovery" as in_progress

**Goal**: Understand the problem space through brief dialogue

**Streamlined Process** (keep it concise - agents will do deep work):

1. **Quick Understanding**
   - Ask: "What are you trying to understand or accomplish?"
   - Ask: "Any specific aspects to focus on?"
   - Ask: "What will you use this research for?"

2. **Scope Clarification** (only if needed)
   - Ask: "Any constraints I should know about?"
   - Ask: "Depth needed: Quick overview or comprehensive analysis?"

3. **Context Gathering** (based on RESEARCH_SCOPE):
   - If codebase research: "Which parts of the codebase should I focus on?"
   - If web research: "Any preferred sources or examples?"
   - If hybrid: Ask both

4. **Manual Simulation Validation** (Optional but Recommended)

   For features involving data processing, algorithms, or complex logic:

   **Ask PM**: "Would you like to manually simulate the behavior before planning?"

   **If PM says yes:**

   a. **Identify Simulation Inputs**:
      - Ask: "Do you have real example inputs we can use for simulation?"
      - If YES: Use actual data from codebase, database samples, or user-provided examples
      - If NO: **CRITICAL FALLBACK** - Create synthetic/example data that represents realistic scenarios

   b. **Synthetic Data Guidance** (when real inputs unavailable):
      ```pseudo
      // For authentication feature (example):
      SYNTHETIC_INPUT_1: { username: "user@example.com", password: "validPassword123" }
      SYNTHETIC_INPUT_2: { username: "invalid", password: "short" }
      SYNTHETIC_INPUT_3: { username: "", password: "" }

      // For payment feature (example):
      SYNTHETIC_INPUT_1: { amount: 100.00, currency: "USD", method: "credit_card" }
      SYNTHETIC_INPUT_2: { amount: 0.01, currency: "EUR", method: "paypal" }
      SYNTHETIC_INPUT_3: { amount: 10000.00, currency: "GBP", method: "invalid" }
      ```

   c. **Manual Simulation Process**:
      - Ask PM to walk through: "Given [input], what should happen step-by-step?"
      - Document: "When [input] ‚Üí Then [expected behavior]"
      - Identify gaps: "What happens if [edge case]?"

   d. **Document Findings**:
      - Inputs used (real or synthetic)
      - Step-by-step expected behavior
      - Edge cases discovered during simulation
      - Gaps or unclear requirements identified

   **Why This Matters**: Prevents building systems based on assumptions. Manual simulation reveals requirements gaps BEFORE planning.

   **When to Skip**: Simple CRUD operations, pure UI changes, or well-understood patterns where behavior is obvious.

**Keep this phase brief** - The specialist agents will conduct the deep research.

**Update TodoWrite**: Mark "Complete interactive discovery" as completed

```bash
# Notify discovery complete
notify_discord "üìù **Discovery Complete**\nBeginning deep research..." "detailed"
```

### Phase 2: Agent Delegation (REQUIRED - Always Use Agents)

**Goal**: Delegate to appropriate specialist agents based on RESEARCH_SCOPE analysis from Step 0d.

**Critical Rule**: ALWAYS delegate to at least one agent. Never use direct tools for research.

---

#### Scenario A: Codebase-Only Research

**If RESEARCH_SCOPE = "codebase":**

**Update TodoWrite**: Mark "Complete codebase exploration" as in_progress

**Delegate to Explore Agent:**

```text
Use the Task tool with subagent_type="Explore":

Prompt:
Explore the codebase with very thorough depth.

Research topic: [user's research topic]

Focus areas (from Phase 1 discovery):
- [specific areas identified]

Please find:
1. Relevant files and their purposes (with file:line references)
2. Existing patterns and architectures used
3. Reusable components and utilities
4. Integration points and dependencies
5. Potential gotchas or edge cases

Provide a comprehensive report on how the codebase handles this topic.

**IMPORTANT**: DO NOT create any files or documents. Return your findings inline only. Document creation happens later if the user requests it.
```

**Wait for Explore agent to complete.**

**Update TodoWrite**:
- Mark "Complete research (codebase and/or web)" as completed

---

#### Scenario B: Web-Only Research

**If RESEARCH_SCOPE = "web":**

**Update TodoWrite**: Mark "Complete web research (if needed)" as in_progress

**Delegate to Master-Research-Agent:**

```text
Use the Task tool with subagent_type="rptc:master-research-agent":

Prompt:
Use the default thinking mode from configuration.

Research [specific topic] for:
1. Best practices and industry standards
2. Common implementation patterns with examples
3. Potential pitfalls and solutions
4. Library/framework recommendations (if applicable)
5. Real-world examples from production systems
6. Performance and security considerations

Focus on actionable insights for implementing [feature] in [tech stack].
Return comprehensive web research report with citations.

**IMPORTANT**: DO NOT create any files or documents. Return your findings inline only. Document creation happens later if the user requests it.
```

**Wait for master-research-agent to complete.**

**Update TodoWrite**:
- Mark "Complete research (codebase and/or web)" as completed

---

#### Scenario C: Hybrid Research (PARALLEL EXECUTION)

**If RESEARCH_SCOPE = "hybrid":**

**Update TodoWrite**: Mark BOTH "Complete codebase exploration" AND "Complete web research (if needed)" as in_progress **simultaneously**

**Delegate to BOTH agents in PARALLEL** (single message with TWO Task tool calls):

**Task 1 - Explore Agent:**
```text
Use the Task tool with subagent_type="Explore":

Prompt:
Explore the codebase with very thorough depth.

Research topic: [user's research topic]

Focus: Understanding our current implementation
- How do we currently handle [topic]?
- What patterns are we using?
- What files and components are involved?
- Any existing issues or technical debt?

Provide detailed analysis of current implementation.

**IMPORTANT**: DO NOT create any files or documents. Return your findings inline only. Document creation happens later if the user requests it.
```

**Task 2 - Master-Research-Agent (in same message):**
```text
Use the Task tool with subagent_type="rptc:master-research-agent":

Prompt:
Use the default thinking mode from configuration.

Research [specific topic] for external context:
1. Industry best practices and standards
2. How other organizations solve this problem
3. Modern patterns and approaches
4. Security and performance benchmarks
5. Recommended tools/libraries

Focus on external insights to compare against our current implementation.

**IMPORTANT**: DO NOT create any files or documents. Return your findings inline only. Document creation happens later if the user requests it.
```

**CRITICAL**: Execute BOTH Task tool calls in a SINGLE message to run agents in parallel.

**Wait for BOTH agents to complete before proceeding.**

**Update TodoWrite**:
- Mark "Complete research (codebase and/or web)" as completed

### Phase 3: Findings Synthesis (REQUIRED)

**Update TodoWrite**: Mark "Present findings to PM" as in_progress

**Goal**: Synthesize findings from agent(s) into clear, actionable format.

**Synthesis Based on Research Scope:**

**If codebase-only research (Explore agent results):**
- Present codebase findings from Explore agent
- Include file:line references
- Note existing patterns and architecture
- Highlight reusable components

**If web-only research (master-research-agent results):**
- Present web research findings
- Include citations and confidence levels
- Summarize best practices and patterns
- List recommended tools/libraries

**If hybrid research (both agents):**
- **Present BOTH sets of findings**
- **Comparison section**: How does our implementation compare to industry standards?
- **Gap analysis**: What are we missing? What are we doing well?
- **Recommendations**: Based on comparison (hybrid mode can make recommendations)

**Present findings with neutral, exploratory tone** (except hybrid mode which can recommend).

**Update TodoWrite**: Mark "Present findings to PM" as completed

---

## Phase 4: Present Findings and Casual Save Offer

**Update TodoWrite**: Mark "Present findings inline" as in_progress

### Step 1: Present Findings Inline

Display detailed findings using comprehensive template structure:

#### Summary
[2-3 sentence overview of findings]

#### Codebase Analysis (if applicable)
**Relevant Files:**
- `path/to/file.ext:line` - [description]

**Existing Patterns Found:**
- [Pattern 1]
- [Pattern 2]

**Reusable Components:**
- [Component 1]
- [Component 2]

#### Web Research (if applicable)
**Key Resources:**
- [Resource 1]
- [Resource 2]

**Best Practices:**
- [Practice 1]
- [Practice 2]

#### Comparison & Gap Analysis (if hybrid mode)
**Existing vs. Best Practice:**
- [Gap 1]
- [Gap 2]

#### Implementation Options (if identified)
**Option 1:** [Approach A]
- Pros: [...]
- Cons: [...]

**Option 2:** [Approach B]
- Pros: [...]
- Cons: [...]

#### Common Pitfalls
- [Pitfall 1]
- [Pitfall 2]

#### Key Takeaways
- [Takeaway 1]
- [Takeaway 2]
- [Takeaway 3]

**Update TodoWrite**: Mark "Present findings inline" as completed

---

### Step 2: Casual Save Offer (Non-Blocking)

Present offer WITHOUT waiting:

```text
üíæ I can save this research report in HTML or Markdown format if you'd like.

Just let me know "save as html" or "save as md" (or both).
```

**End command naturally** - no wait, no blocking.

User can respond in next message if interested.

**Note**: All TodoWrite tasks are now completed (discovery, research, and presentation are done). If user requests save in next message, Phase 5 will execute.

---

## Phase 5: Save Report (Triggered by User Request)

**This phase only executes if user responds to casual save offer.**

### Step 5a: Parse Save Request

Detect format preference from user's message:

**Format detection patterns:**
- "save as html" OR "html" ‚Üí format=html
- "save as md" OR "markdown" OR "md" ‚Üí format=md
- "both" ‚Üí format=both

**If format unclear** (e.g., "yes", "save it", "please save"):
Ask: "Save as HTML or Markdown? (or both)"

Wait for clarification before proceeding.

### Step 5b: Acknowledge and Add Todo

Acknowledge: "Saving as [format]..."

**Dynamically add 4th todo:**

Use TodoWrite to append save todo (mark in_progress):

```json
{
  "tool": "TodoWrite",
  "todos": [
    {
      "content": "Complete interactive discovery",
      "status": "completed",
      "activeForm": "Conducting interactive discovery"
    },
    {
      "content": "Complete research (codebase and/or web)",
      "status": "completed",
      "activeForm": "Conducting research"
    },
    {
      "content": "Present findings inline",
      "status": "completed",
      "activeForm": "Presenting findings"
    },
    {
      "content": "Save research report",
      "status": "in_progress",
      "activeForm": "Saving research report"
    }
  ]
}
```

### Step 5c: Create Output Directory

Generate slug from research topic:

```bash
TOPIC_SLUG=$(echo "${RESEARCH_TOPIC}" | tr '[:upper:]' '[:lower:]' | tr ' ' '-' | tr -cd '[:alnum:]-')
OUTPUT_DIR="${ARTIFACT_LOC}/research/${TOPIC_SLUG}"
```

**Handle duplicates:**
If directory exists, ask user:
- Overwrite existing?
- Create timestamped version?
- Cancel save?

If timestamped or first time:
```bash
mkdir -p "${OUTPUT_DIR}"
```

### Step 5d: Delegate to Sub-Agent(s)

**If format=html:**
Delegate to `html-report-generator` skill:

```markdown
Use the Skill tool with skill_name="rptc:html-report-generator":

Input: Research findings (inline markdown from Phase 4)
Output: `.rptc/research/[slug]/research.html` (professional HTML report)
Theme: [HTML_THEME from config or default "dark"]

Create professional HTML report from research findings.
```

**If format=md:**
Delegate to general-purpose write:

```markdown
Use Write tool to save markdown:

File: `.rptc/research/[slug]/research.md`
Content: [formatted research findings from Phase 4 template]
```

**If format=both:**
Execute both delegations in single message (parallel):
1. Write markdown file
2. Generate HTML report

**Automatic retry logic:**
- If sub-agent fails to write file (file not found after delegation)
- Wait 2 seconds and retry same delegation once
- If still fails after retry: Report error to user with details

### Step 5e: Complete and Report

**Update TodoWrite**: Mark "Save research report" as completed

```json
{
  "content": "Save research report",
  "status": "completed",
  "activeForm": "Saving research report"
}
```

**Report success:**

```text
‚úÖ Research saved successfully!

Files created:
- `.rptc/research/[slug]/research.md` [if md or both]
- `.rptc/research/[slug]/research.html` [if html or both]
```

**If retry failed:**

```text
‚ö†Ô∏è Failed to save report after retry. Files may need manual creation:
- Expected: `.rptc/research/[slug]/[format]`
- Error: [sub-agent error message]

You can retry manually by running the save request again.
```

**Send Discord notification** (if enabled):

```bash
# For successful save
notify_discord "‚úÖ **Research Saved**\nTopic: ${RESEARCH_TOPIC}\nFormat: ${FORMAT_CHOICE}" "summary"

# For failed save
notify_discord "‚ö†Ô∏è **Research Save Failed**\nTopic: ${RESEARCH_TOPIC}\nRetry may be needed" "summary"
```

**End Phase 5**

---

## Interaction Guidelines

### DO:

- ‚úÖ Ask thorough, probing questions
- ‚úÖ Keep asking until you truly understand
- ‚úÖ Present options and trade-offs (not recommendations)
- ‚úÖ Reference SOPs for context (not prescriptions)
- ‚úÖ Challenge assumptions respectfully
- ‚úÖ Search codebase comprehensively
- ‚úÖ Include file:line references
- ‚úÖ Present findings neutrally and clearly
- ‚úÖ End with casual save offer (non-blocking)
- ‚úÖ Let user decide if/when/how to save

### DON'T:

- ‚ùå Rush to solutions
- ‚ùå Make prescriptive recommendations (present options instead)
- ‚ùå Decide which pattern/approach to use (that's planning phase)
- ‚ùå Make assumptions about requirements
- ‚ùå Do web research without permission
- ‚ùå Block waiting for save decision
- ‚ùå Decide scope (that's the PM's job)
- ‚ùå Skip the questioning phase
- ‚ùå Front-load all SOPs (reference as needed)

## Helper Commands Available

You can use these helper commands during research:

- `/rptc:helper-catch-up-quick` - Quick context (2 min)
- `/rptc:helper-catch-up-med` - Medium context (5-10 min)
- `/rptc:helper-catch-up-deep` - Deep analysis (15-30 min)

Use these if you need additional project context.

## Success Criteria

- [ ] Asked enough questions to understand scope
- [ ] Identified options and trade-offs (referenced SOPs for context)
- [ ] Searched codebase thoroughly (if applicable)
- [ ] Listed all relevant files with line numbers
- [ ] Presented clear, neutral findings (no prescriptive recommendations)
- [ ] Presented implementation options with pros/cons
- [ ] Offered casual save option (non-blocking)
- [ ] Command ended naturally (no blocking wait)

---

**Remember**:

- You're the research partner, the PM is the decision maker
- Present options and trade-offs, not recommendations
- Reference SOPs for context and standards (not prescriptions)
- File paths use line numbers for precision (`file.ts:123`)
- Casual save offer at end, but don't wait for response
- User can save later via "save as html/md" message
